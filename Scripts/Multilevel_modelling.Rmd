---
title: "Multilevel modelling"
author: "Ida Dencker"
date: "2024-05-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
pacman::p_load(tidyverse, lme4) 
```


```{r}
#load in data
sentiment_data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/Sentiment CSV files/5_types_sen.csv')

#can check number of distinct values for a column
n_distinct(sentiment_data$ID)
```

# Multilevel modelling (predictive modelling)

List of predictors:
- offentlig_privat
- week
- n_post_day
- municipality
- subcomment
- total_n_comments
- total_n_reactions
- count_like
- count_care
- count_heart
- count_haha
- count_sad
- count_angry
- count_wow
- count_heart

sentiment predictors
- neg_vader
- neu_vader
- pos_vader
- compound_vader
- pos_score_roberta
- neg_score_roberta
- neu_score_roberta
- compound_roberta
- roberta_label
- bert_emotion_label 
- attack
- rec-nition

outcome
- intervention

```{r}
# preprocessing the data

#check class of every column
sapply(sentiment_data, class)

#factorize data
# data that cant be 'integer' numbers and have levels are transformed, e.g we can't have 7,3 weeks or 1,2 municipality == transformed 
sentiment_data <- sentiment_data %>%
  mutate(
    intervention = as.factor(intervention),
    main_post = as.factor(main_post),
    week = as.factor(week),
    subcomment = as.factor(subcomment),
    municipality = as.factor(municipality),
    offentlig_privat = as.factor(offentlig_privat),
    roberta_label = as.factor(roberta_label),
    name_abbreviation = as.factor(name_abbreviation)
  )

#should ID be level??

#check the levels look right 
sapply(sentiment_data, levels)

#can check the number of levels for a factor column
nlevels(sentiment_data$name_abbreviation)

```

#getting an idea of how the data looks, to understand the output of the models better

```{r}
library(ggplot2)
library(gridExtra)

# Plotting positive scores
p1 <- ggplot(sentiment_data, aes(x = intervention, y = pos_score_roberta)) +
  geom_bar(stat = "summary", fun = "mean", fill = "skyblue", color = "black") +
  labs(title = "Positive") +
  theme_minimal()

# Plotting neutral scores
p2 <- ggplot(sentiment_data, aes(x = intervention, y = neu_score_roberta)) +
  geom_bar(stat = "summary", fun = "mean", fill = "lightgreen", color = "black") +
  labs(title = "Neutral") +
  theme_minimal()

# Plotting negative scores
p3 <- ggplot(sentiment_data, aes(x = intervention, y = neg_score_roberta)) +
  geom_bar(stat = "summary", fun = "mean", fill = "salmon", color = "black") +
  labs(title = "Negative") +
  theme_minimal()

# Plotting compound scores
p4 <- ggplot(sentiment_data, aes(x = intervention, y = compound_roberta)) +
  geom_bar(stat = "summary", fun = "mean", fill = "lightgrey", color = "black") +
  labs(title = "Compound") +
  theme_minimal()


# Combining plots
grid.arrange(p1, p2, p3, p4, ncol = 2)


#looking here we see that when the intervention is yes the comments are generally more negative (lower pos score + higher neg score + lower compound score). This is good to know before starting to model the effect of intervention. So looking at this, we expect that an intervention (intervention==yes) will entail a more negative sentiment in comments compared to no intervention (intervention == no)

```


Now we can start on making multilevel logistic regression models predicting intervention, i.e intervention as a function of different predictors

The data has a 4 level structure with nestedness: comments (here comments are represented by a sentiment score) nested in posts (ID) nested in politicians (name_abbreviation) nested in kommune (municipality)


```{r}
#First: check level of the outcome variable 
levels(sentiment_data$intervention)
#first level (here no) is encoded as 0 and the second level (here yes) is encoded as 1, estimates we are getting are **log odds of level 1** i.e. the probability of the intervention being yes 
```

read: https://rips-irsp.com/articles/10.5334/irsp.90

predictors
- compound_vader
- compound_roberta
- bert_emotion_label
- attack
- rec-nition
- municipality 
- offentlig_privat
- total_n_comments
- total_n_reactions
- count_XX


a '/' is the syntax used to account for nestedness. Nested random effects are hierarchical, with one level nested within another meaning that the same politician e.g. cant be part of multiple municipalities 

It is different from using ':' which is used to specify crossed random effects. Crossed random effects are random effects that are not nested within each other but are crossed with each other. For example, if you have random effects for both municipalities and politicians, and each politician can make posts in multiple municipalities and each municipality can have multiple politicians, you might use the :` syntax to specify crossed random effects:


```{r}
#remember that in logistic regression coefficients are a on log-oods scale = positive means increase in possibility
##log odds of intervention is predicted by compound score (fixed effect) allowing the model to vary by group




##INTERCEPT ONLY MODEL:

#Below are the commands to run an empty model, that is, a model containing no predictors, 
empty_model <- glmer(intervention ~ ( 1 | ID), data=sentiment_data, family = "binomial")
summary(empty_model)
#There is substantial variability in the intercept across different levels of ID (Std.Dev. = 88.07), suggesting that the random effect of ID is important in the model.
# The intercept of -17.689 is significantly different from zero, indicating that on average, without considering the random effect, the log odds of intervention are very low. That makes sence since there are way more no-intervention posts, so the general probabilty of the post being intervention is very low




## SIMPLE LOGISTIC REGRESSION MODEL (no mixed effects):

#no mixed effects model
no_mixed_model <- glm(intervention ~ compound_roberta,family=binomial(link='logit'),data=sentiment_data)
summary(no_mixed_model)
#no random effects: assume all data are independent from each other (not the case here)
#when the compound score increase with 1 (more positive sentiment) the log odds of the intervention being yes decreases with -0.59, i.e. more positive sentiment entails a lower probability of the intervention being yes, in accordance with what the plots above are showing. The predictor is siggnificant here.  



## 2-LEVEL MODEL (Comments nested in ID):
two_level_model <- glmer(intervention ~ compound_roberta + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model)
# allowing to vary by ID 
# The intercept of the fixed effects are stil negative, indicating that in increse in compund decreses the possibility of intervention. After having accounted for the fact that some of the variance in sentiment can be accounted for by ID, not 'much is left' for the model to explaing the compund by the intervention




## 3-LEVEL MODEL (comments nested in ID nested in politicians):
three_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation), data = sentiment_data, family = binomial)
summary(three_level_model)
# Same case as with the 2-level model 




## 4-LEVEL MODEL (comments nested in ID nested in politicians nested in municipality):
four_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation/municipality), data = sentiment_data, family = binomial)
summary(four_level_model)




## NO HIERARCHY MODEL

#a model with separate random intercepts for each grouping variable without explicitly specifying the nesting. This is assuming that the grouping variables are independent of each other.
no_hier_model <- glmer(intervention ~ compound_roberta + (1| ID) + (1| name_abbreviation) + (1| municipality), data = sentiment_data, family = binomial)
summary(no_hier_model)


#maybe make a model only varying by ID, 1 only my politician, 1 only by municipality?


#compare the different models like this:
f1 <- performance::model_performance(empty_model, metrics= "common")
f2 <- performance::model_performance(no_mixed_model, metrics= "common")
f3 <- performance::model_performance(two_level_model, metrics= "common")
f4 <- performance::model_performance(three_level_model, metrics= "common")
f5 <- performance::model_performance(four_level_model, metrics= "common")
f6 <- performance::model_performance(no_hier_model, metrics= "common")

print("empty_model:")
f1
print("no_mixed_model:")
f2
print("two_level_model:")
f3
print("three_level_model:")
f4
print("four_level_model:")
f5
print("no_hier_model:")
f6

# The empty model and and the 2 level models has the lowest AIC indicating better model performance. These howver are not very useful to us. The empty model has obviously no predictors. The 2-level model

```

```{r}
# make a plot like this one: https://blogs.uoregon.edu/rclub/2016/04/05/plotting-your-logistic-regression-models/

#like i did for a previous exam
```


```{r}
#can do some simple plotting 
plot(pos_score_roberta ~ neg_score_roberta, data = sentiment_data, main = "pos_score_roberta ~ neg_score_roberta") 
```


# predcting the sentiment, i.e. can the sentiment of the comments be predicted by e.g. municipality, n_likes, n_hearts, politician (name_abbreviation)

```{r}

```


#investigate intercorrelation between variables
e.g is there a correlation between municipality and sentiment, between sentiment and n_likes etc.

```{r}
# plotting and calculations 
```

