{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63128c63-02ec-4562-bba7-13b7c7c6f10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21cfbf2-1be0-4469-b6c0-cb9f766a9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de363de9-229b-458f-88e6-20df3bf81af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in data\n",
    "\n",
    "data = pd.read_csv('/Users/idahelenedencker/Desktop/STANDBY/all_files_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9163aba5-cb59-4f6c-9099-a6cc618e4d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>file_name</th>\n",
       "      <th>main_post</th>\n",
       "      <th>name_abbreviation</th>\n",
       "      <th>offentlig_privat</th>\n",
       "      <th>date_post</th>\n",
       "      <th>n_post_day</th>\n",
       "      <th>week</th>\n",
       "      <th>group</th>\n",
       "      <th>intervention</th>\n",
       "      <th>...</th>\n",
       "      <th>has_comments</th>\n",
       "      <th>total_n_comments</th>\n",
       "      <th>n_total_reactions</th>\n",
       "      <th>count_like</th>\n",
       "      <th>count_heart</th>\n",
       "      <th>count_haha</th>\n",
       "      <th>count_care</th>\n",
       "      <th>count_angry</th>\n",
       "      <th>count_sad</th>\n",
       "      <th>count_wow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1601</td>\n",
       "      <td>YiYiP-3005-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>3005</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>control</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>YiYiP-2905-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2905</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>control</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1599</td>\n",
       "      <td>YiYiP-2806-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2806</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>control</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1599</td>\n",
       "      <td>YiYiP-2806-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2806</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>control</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1598</td>\n",
       "      <td>YiYiP-2705-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2705</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>control</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15460</th>\n",
       "      <td>1</td>\n",
       "      <td>AaPeO-0105-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>AaPe</td>\n",
       "      <td>O</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>treatment</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15461</th>\n",
       "      <td>1</td>\n",
       "      <td>AaPeO-0105-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>AaPe</td>\n",
       "      <td>O</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>treatment</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15462</th>\n",
       "      <td>1</td>\n",
       "      <td>AaPeO-0105-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>AaPe</td>\n",
       "      <td>O</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>treatment</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15463</th>\n",
       "      <td>1</td>\n",
       "      <td>AaPeO-0105-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>AaPe</td>\n",
       "      <td>O</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>treatment</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15464</th>\n",
       "      <td>1</td>\n",
       "      <td>AaPeO-0105-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>AaPe</td>\n",
       "      <td>O</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>treatment</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15465 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID               file_name  main_post name_abbreviation  \\\n",
       "0      1601  YiYiP-3005-1_slut.json          1              YiYi   \n",
       "1      1600  YiYiP-2905-1_slut.json          1              YiYi   \n",
       "2      1599  YiYiP-2806-1_slut.json          1              YiYi   \n",
       "3      1599  YiYiP-2806-1_slut.json          0              YiYi   \n",
       "4      1598  YiYiP-2705-1_slut.json          1              YiYi   \n",
       "...     ...                     ...        ...               ...   \n",
       "15460     1  AaPeO-0105-1_slut.json          0              AaPe   \n",
       "15461     1  AaPeO-0105-1_slut.json          0              AaPe   \n",
       "15462     1  AaPeO-0105-1_slut.json          0              AaPe   \n",
       "15463     1  AaPeO-0105-1_slut.json          0              AaPe   \n",
       "15464     1  AaPeO-0105-1_slut.json          0              AaPe   \n",
       "\n",
       "      offentlig_privat  date_post  n_post_day  week      group intervention  \\\n",
       "0                    P       3005           1     5    control           no   \n",
       "1                    P       2905           1     5    control           no   \n",
       "2                    P       2806           1     9    control           no   \n",
       "3                    P       2806           1     9    control           no   \n",
       "4                    P       2705           1     4    control           no   \n",
       "...                ...        ...         ...   ...        ...          ...   \n",
       "15460                O        105           1     1  treatment           no   \n",
       "15461                O        105           1     1  treatment           no   \n",
       "15462                O        105           1     1  treatment           no   \n",
       "15463                O        105           1     1  treatment           no   \n",
       "15464                O        105           1     1  treatment           no   \n",
       "\n",
       "       ... has_comments total_n_comments n_total_reactions  count_like  \\\n",
       "0      ...            0                0                25          22   \n",
       "1      ...            0                0                34          32   \n",
       "2      ...            1                1                31          29   \n",
       "3      ...            1                1                 1           1   \n",
       "4      ...            0                0                11          11   \n",
       "...    ...          ...              ...               ...         ...   \n",
       "15460  ...            1                8                 1           1   \n",
       "15461  ...            1                8                 1           1   \n",
       "15462  ...            1                8                 1           1   \n",
       "15463  ...            1                8                 1           1   \n",
       "15464  ...            1                8                 0           0   \n",
       "\n",
       "       count_heart count_haha  count_care count_angry count_sad count_wow  \n",
       "0                3          0           0           0         0         0  \n",
       "1                2          0           0           0         0         0  \n",
       "2                2          0           0           0         0         0  \n",
       "3                0          0           0           0         0         0  \n",
       "4                0          0           0           0         0         0  \n",
       "...            ...        ...         ...         ...       ...       ...  \n",
       "15460            0          0           0           0         0         0  \n",
       "15461            0          0           0           0         0         0  \n",
       "15462            0          0           0           0         0         0  \n",
       "15463            0          0           0           0         0         0  \n",
       "15464            0          0           0           0         0         0  \n",
       "\n",
       "[15465 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a744a96-4ef6-4738-82a2-cf21f9dd9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#START by removing all rows where text is empty, THEN add unique_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7925388-5986-4ed2-b0a6-8e2a8201cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Reset index starting from 1\n",
    "data.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# Add 1 to the index to start from 1 instead of 0\n",
    "data['unique_ID'] = data.index + 1\n",
    "\n",
    "# If you want to move the ID column to the beginning\n",
    "# Reorder the columns\n",
    "data = data[['unique_ID'] + [col for col in data.columns if col != 'unique_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649f3a6b-a3f1-4319-a6d9-b89ccc8a00f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_ID</th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>file_name</th>\n",
       "      <th>main_post</th>\n",
       "      <th>name_abbreviation</th>\n",
       "      <th>offentlig_privat</th>\n",
       "      <th>date_post</th>\n",
       "      <th>n_post_day</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>has_comments</th>\n",
       "      <th>total_n_comments</th>\n",
       "      <th>n_total_reactions</th>\n",
       "      <th>count_like</th>\n",
       "      <th>count_heart</th>\n",
       "      <th>count_haha</th>\n",
       "      <th>count_care</th>\n",
       "      <th>count_angry</th>\n",
       "      <th>count_sad</th>\n",
       "      <th>count_wow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>YiYiP-3005-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>3005</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>YiYiP-2905-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2905</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1599</td>\n",
       "      <td>YiYiP-2806-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2806</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1599</td>\n",
       "      <td>YiYiP-2806-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2806</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1598</td>\n",
       "      <td>YiYiP-2705-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2705</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15460</th>\n",
       "      <td>15461</td>\n",
       "      <td>15460</td>\n",
       "      <td>1</td>\n",
       "      <td>AaPeO-0105-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>AaPe</td>\n",
       "      <td>O</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15461</th>\n",
       "      <td>15462</td>\n",
       "      <td>15461</td>\n",
       "      <td>1</td>\n",
       "      <td>AaPeO-0105-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>AaPe</td>\n",
       "      <td>O</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15462</th>\n",
       "      <td>15463</td>\n",
       "      <td>15462</td>\n",
       "      <td>1</td>\n",
       "      <td>AaPeO-0105-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>AaPe</td>\n",
       "      <td>O</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15463</th>\n",
       "      <td>15464</td>\n",
       "      <td>15463</td>\n",
       "      <td>1</td>\n",
       "      <td>AaPeO-0105-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>AaPe</td>\n",
       "      <td>O</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15464</th>\n",
       "      <td>15465</td>\n",
       "      <td>15464</td>\n",
       "      <td>1</td>\n",
       "      <td>AaPeO-0105-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>AaPe</td>\n",
       "      <td>O</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15465 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_ID  index    ID               file_name  main_post  \\\n",
       "0              1      0  1601  YiYiP-3005-1_slut.json          1   \n",
       "1              2      1  1600  YiYiP-2905-1_slut.json          1   \n",
       "2              3      2  1599  YiYiP-2806-1_slut.json          1   \n",
       "3              4      3  1599  YiYiP-2806-1_slut.json          0   \n",
       "4              5      4  1598  YiYiP-2705-1_slut.json          1   \n",
       "...          ...    ...   ...                     ...        ...   \n",
       "15460      15461  15460     1  AaPeO-0105-1_slut.json          0   \n",
       "15461      15462  15461     1  AaPeO-0105-1_slut.json          0   \n",
       "15462      15463  15462     1  AaPeO-0105-1_slut.json          0   \n",
       "15463      15464  15463     1  AaPeO-0105-1_slut.json          0   \n",
       "15464      15465  15464     1  AaPeO-0105-1_slut.json          0   \n",
       "\n",
       "      name_abbreviation offentlig_privat  date_post  n_post_day  week  ...  \\\n",
       "0                  YiYi                P       3005           1     5  ...   \n",
       "1                  YiYi                P       2905           1     5  ...   \n",
       "2                  YiYi                P       2806           1     9  ...   \n",
       "3                  YiYi                P       2806           1     9  ...   \n",
       "4                  YiYi                P       2705           1     4  ...   \n",
       "...                 ...              ...        ...         ...   ...  ...   \n",
       "15460              AaPe                O        105           1     1  ...   \n",
       "15461              AaPe                O        105           1     1  ...   \n",
       "15462              AaPe                O        105           1     1  ...   \n",
       "15463              AaPe                O        105           1     1  ...   \n",
       "15464              AaPe                O        105           1     1  ...   \n",
       "\n",
       "      has_comments total_n_comments n_total_reactions count_like count_heart  \\\n",
       "0                0                0                25         22           3   \n",
       "1                0                0                34         32           2   \n",
       "2                1                1                31         29           2   \n",
       "3                1                1                 1          1           0   \n",
       "4                0                0                11         11           0   \n",
       "...            ...              ...               ...        ...         ...   \n",
       "15460            1                8                 1          1           0   \n",
       "15461            1                8                 1          1           0   \n",
       "15462            1                8                 1          1           0   \n",
       "15463            1                8                 1          1           0   \n",
       "15464            1                8                 0          0           0   \n",
       "\n",
       "       count_haha  count_care count_angry  count_sad count_wow  \n",
       "0               0           0           0          0         0  \n",
       "1               0           0           0          0         0  \n",
       "2               0           0           0          0         0  \n",
       "3               0           0           0          0         0  \n",
       "4               0           0           0          0         0  \n",
       "...           ...         ...         ...        ...       ...  \n",
       "15460           0           0           0          0         0  \n",
       "15461           0           0           0          0         0  \n",
       "15462           0           0           0          0         0  \n",
       "15463           0           0           0          0         0  \n",
       "15464           0           0           0          0         0  \n",
       "\n",
       "[15465 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b6633f-1f2f-4b78-b834-3163e7e0ee29",
   "metadata": {},
   "source": [
    "## Doing different sentiment analysis on the comments (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4381e63-0f4b-4371-ba85-0560abda9a15",
   "metadata": {},
   "source": [
    "### VADER multilaguage (simple model)\n",
    "\n",
    "Takes each word as neg, pos or neutral and provides sentiment scores based on the words used. Note that the model does not understand relations between words, e.g. negation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b9f66b-ba67-4660-86cb-590f5a43476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (4.66.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ed5103-6c45-4a4e-9448-224d7ac6626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ed783d8-cdea-4c2c-a4ad-61d5367ae9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 34)\n"
     ]
    }
   ],
   "source": [
    "#make a shortened version\n",
    "df = data.head(500)\n",
    "print(df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe3740-8566-4948-8627-5165505b3532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c18de1f-ec26-446d-bb89-9a333edd78bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NA or empty content in the 'text' column\n",
    "#df = df.dropna(subset=['text'])\n",
    "\n",
    "df = df[df['text'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bcfbb7-99ef-4d03-811e-cc04a164e486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59ee0986-1d9c-422b-a90f-bfc0496a202f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_ID</th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>file_name</th>\n",
       "      <th>main_post</th>\n",
       "      <th>name_abbreviation</th>\n",
       "      <th>offentlig_privat</th>\n",
       "      <th>date_post</th>\n",
       "      <th>n_post_day</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>has_comments</th>\n",
       "      <th>total_n_comments</th>\n",
       "      <th>n_total_reactions</th>\n",
       "      <th>count_like</th>\n",
       "      <th>count_heart</th>\n",
       "      <th>count_haha</th>\n",
       "      <th>count_care</th>\n",
       "      <th>count_angry</th>\n",
       "      <th>count_sad</th>\n",
       "      <th>count_wow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>YiYiP-3005-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>3005</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>YiYiP-2905-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2905</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1599</td>\n",
       "      <td>YiYiP-2806-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2806</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1598</td>\n",
       "      <td>YiYiP-2705-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2705</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1597</td>\n",
       "      <td>YiYiP-2506-2_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>495</td>\n",
       "      <td>1538</td>\n",
       "      <td>YiAkP-0806-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiAk</td>\n",
       "      <td>P</td>\n",
       "      <td>806</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>496</td>\n",
       "      <td>1538</td>\n",
       "      <td>YiAkP-0806-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiAk</td>\n",
       "      <td>P</td>\n",
       "      <td>806</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>497</td>\n",
       "      <td>1538</td>\n",
       "      <td>YiAkP-0806-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiAk</td>\n",
       "      <td>P</td>\n",
       "      <td>806</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "      <td>1538</td>\n",
       "      <td>YiAkP-0806-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiAk</td>\n",
       "      <td>P</td>\n",
       "      <td>806</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>499</td>\n",
       "      <td>1538</td>\n",
       "      <td>YiAkP-0806-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiAk</td>\n",
       "      <td>P</td>\n",
       "      <td>806</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_ID  index    ID               file_name  main_post  \\\n",
       "0            1      0  1601  YiYiP-3005-1_slut.json          1   \n",
       "1            2      1  1600  YiYiP-2905-1_slut.json          1   \n",
       "2            3      2  1599  YiYiP-2806-1_slut.json          1   \n",
       "4            5      4  1598  YiYiP-2705-1_slut.json          1   \n",
       "5            6      5  1597  YiYiP-2506-2_slut.json          1   \n",
       "..         ...    ...   ...                     ...        ...   \n",
       "495        496    495  1538  YiAkP-0806-1_slut.json          0   \n",
       "496        497    496  1538  YiAkP-0806-1_slut.json          0   \n",
       "497        498    497  1538  YiAkP-0806-1_slut.json          0   \n",
       "498        499    498  1538  YiAkP-0806-1_slut.json          0   \n",
       "499        500    499  1538  YiAkP-0806-1_slut.json          0   \n",
       "\n",
       "    name_abbreviation offentlig_privat  date_post  n_post_day  week  ...  \\\n",
       "0                YiYi                P       3005           1     5  ...   \n",
       "1                YiYi                P       2905           1     5  ...   \n",
       "2                YiYi                P       2806           1     9  ...   \n",
       "4                YiYi                P       2705           1     4  ...   \n",
       "5                YiYi                P       2506           2     8  ...   \n",
       "..                ...              ...        ...         ...   ...  ...   \n",
       "495              YiAk                P        806           1     6  ...   \n",
       "496              YiAk                P        806           1     6  ...   \n",
       "497              YiAk                P        806           1     6  ...   \n",
       "498              YiAk                P        806           1     6  ...   \n",
       "499              YiAk                P        806           1     6  ...   \n",
       "\n",
       "    has_comments total_n_comments n_total_reactions count_like count_heart  \\\n",
       "0              0                0                25         22           3   \n",
       "1              0                0                34         32           2   \n",
       "2              1                1                31         29           2   \n",
       "4              0                0                11         11           0   \n",
       "5              1                1                32         23           0   \n",
       "..           ...              ...               ...        ...         ...   \n",
       "495            1              391                 1          0           0   \n",
       "496            1              391                 1          0           0   \n",
       "497            1              391                 1          0           0   \n",
       "498            1              391                 1          0           0   \n",
       "499            1              391                 1          0           0   \n",
       "\n",
       "     count_haha  count_care count_angry  count_sad count_wow  \n",
       "0             0           0           0          0         0  \n",
       "1             0           0           0          0         0  \n",
       "2             0           0           0          0         0  \n",
       "4             0           0           0          0         0  \n",
       "5             0           0           0          9         0  \n",
       "..          ...         ...         ...        ...       ...  \n",
       "495           0           1           0          0         0  \n",
       "496           0           1           0          0         0  \n",
       "497           0           1           0          0         0  \n",
       "498           0           1           0          0         0  \n",
       "499           0           1           0          0         0  \n",
       "\n",
       "[444 rows x 34 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54165c6-38fa-40a6-b365-228cb3c2f1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4ff7a-13e3-401c-80bb-f78fd1f29c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ffba30-1e9c-4dd7-b7a6-2480505258e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all rows that has NA or no content in the 'text' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f322c49b-7ca7-41c4-8514-c514242216f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping vaderSentiment as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting vader-multi\n",
      "  Downloading vader_multi-3.2.2.1-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from vader-multi) (2.31.0)\n",
      "Collecting translatte (from vader-multi)\n",
      "  Downloading translatte-0.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->vader-multi) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->vader-multi) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->vader-multi) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->vader-multi) (2023.7.22)\n",
      "Downloading vader_multi-3.2.2.1-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading translatte-0.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: translatte, vader-multi\n",
      "Successfully installed translatte-0.1 vader-multi-3.2.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall vaderSentiment\n",
    "%pip install vader-multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b639f51-057c-4338-90ec-13e1ba6b569e",
   "metadata": {},
   "source": [
    "obs if command below gives an error like: \n",
    "\n",
    "URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>\n",
    "\n",
    "do: \n",
    "\n",
    "Åbn Finder (Open Finder).\n",
    "Gå til din Macintosh HD (Navigate to your Macintosh HD).\n",
    "Åbn mappen \"APPS\" (Open the \"APPS\" folder).\n",
    "Find din Python-mappe (Find your Python folder), which might be named something like \"Python3.6\" or \"Python3.9\". (Python3.11 hedder den på min)\n",
    "Dobbeltklik på \"Install Certificates.command\" (Double-click on \"Install Certificates.command\") for at køre kommandoen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6358b7-9bc7-43e7-badc-a31cb9aa1089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting translatte\n",
      "  Using cached translatte-0.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Using cached translatte-0.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: translatte\n",
      "Successfully installed translatte-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install translatte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73dea5ba-55d2-4e26-ba0f-69dccb692940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "#analyzer.polarity_scores(\"VADER is smart, handsome, and funny.\")\n",
    "\n",
    "#analyzer.polarity_scores(\"VADER sind nicht sehr gut\")\n",
    "sia.polarity_scores(\"VADER er bare mega dårligt, hader den!!\")\n",
    "\n",
    "sia.polarity_scores(df['text'][400])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e21ed9-0f75-43e3-a4d3-7a4ecd0ddbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b376562-f5a6-48b5-baee-5c01804d8424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd45a3f5-265d-4488-b3e6-022af15eabf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: translatte 0.1\n",
      "Uninstalling translatte-0.1:\n",
      "  Would remove:\n",
      "    /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/translatte-0.1.dist-info/*\n",
      "    /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/translatte/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muninstall translatte\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mY\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "%pip uninstall translatte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "548a93e0-e296-48e4-a95c-2473306cdb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.11.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b9c6cc6-a1f7-4017-a02a-7bbd0f976378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import nltk\n",
    ">>> nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "490ec544-0e09-4f58-b68a-2bd45543a507",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SentimentIntensityAnalyzer.polarity_scores() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Iterate over each element in the 'text' column and analyze its sentiment\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 16\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43msia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     sentiment_scores\u001b[38;5;241m.\u001b[39mappend(scores)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Convert the list of dictionaries to a DataFrame\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: SentimentIntensityAnalyzer.polarity_scores() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import emoji\n",
    "\n",
    "# Assuming you already have imported your DataFrame df\n",
    "\n",
    "sia = SentimentIntensityAnalyzer\n",
    "\n",
    "# Create an empty list to store the sentiment scores\n",
    "sentiment_scores = []\n",
    "\n",
    "# Iterate over each element in the 'text' column and analyze its sentiment\n",
    "for text in df['text']:\n",
    "    scores = sia.polarity_scores(text, )\n",
    "    sentiment_scores.append(scores)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "sentiment_df = pd.DataFrame(sentiment_scores)\n",
    "\n",
    "# Concatenate the sentiment DataFrame with the original DataFrame\n",
    "df_with_sentiment = pd.concat([df, sentiment_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b891b-af75-46c0-b5e5-c09a42c51914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f41a758-71b0-4026-bb35-e43effa05eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca02ca4-f48b-4678-93bb-cf361ce8b917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cf1d6b-777d-4454-899c-834d827eb1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14ca1892-956c-4942-b3ea-ef83b4c4693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.66.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (5.10.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: backcall in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d173fc9-cc0f-4b8d-9b2b-48b90fb5009f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: widgetsnbextension in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.0.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dfdaea6-ed84-48cd-a378-acde2fc7308e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (5.10.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: backcall in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert run server troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5650dd97-39c7-4e85-a60d-cf419679dc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503fbae9ccde48359ae6c59ed28c22c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "SentimentIntensityAnalyzer.polarity_scores() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m myid \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m res[myid] \u001b[38;5;241m=\u001b[39m \u001b[43msia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: SentimentIntensityAnalyzer.polarity_scores() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "from ipywidgets import FloatProgress\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = row['text']\n",
    "    myid = row['unique_ID']\n",
    "    res[myid] = sia.polarity_scores('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f44622a7-36c5-44f0-b107-bb6b9d4cebda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "sentences=[\"hello\",\"why is it not working?!\"]\n",
    "for sentence in sentences:\n",
    "    ss = sid.polarity_scores(sentence) \n",
    "print (ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9784e10e-f095-4438-afd0-e25035ccf0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vegera Êzîdîyan ji Kampan bo Şingalê'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d812aff-a814-4e7a-b2a3-6a92c2c8dc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b11aef-a5e0-474c-8d6c-31cdc58510f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe368e-14b6-4575-801c-88c74abe53ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab72cc-2a9c-4e31-9462-c4e1673bc700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26394e5-cfa4-4ea1-b780-68fb1821355c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92bbe2-5765-4968-a96f-f85145c46117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb223ab6-5ab8-44a1-bd18-a9fd1b93c5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bded030f-2bfe-4667-8b99-20def6758958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.772, 'pos': 0.228, 'compound': 0.9451}\n",
      "{'neg': 0.087, 'neu': 0.913, 'pos': 0.0, 'compound': -0.5574}\n",
      "{'neg': 0.0, 'neu': 0.31, 'pos': 0.69, 'compound': 0.9638}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.21, 'neu': 0.67, 'pos': 0.121, 'compound': -0.4588}\n",
      "{'neg': 0.0, 'neu': 0.465, 'pos': 0.535, 'compound': 0.5574}\n",
      "{'neg': 0.0, 'neu': 0.795, 'pos': 0.205, 'compound': 0.995}\n",
      "{'neg': 0.0, 'neu': 0.305, 'pos': 0.695, 'compound': 0.8442}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.435, 'pos': 0.565, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.283, 'pos': 0.717, 'compound': 0.8225}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.408, 'pos': 0.592, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'compound': 0.9371}\n",
      "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.506, 'pos': 0.494, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.29, 'pos': 0.71, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.435, 'pos': 0.565, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.208, 'pos': 0.792, 'compound': 0.8225}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.8957}\n",
      "{'neg': 0.0, 'neu': 0.493, 'pos': 0.507, 'compound': 0.8834}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.145, 'pos': 0.855, 'compound': 0.7096}\n",
      "{'neg': 0.169, 'neu': 0.448, 'pos': 0.383, 'compound': 0.6486}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.704, 'pos': 0.296, 'compound': 0.2732}\n",
      "{'neg': 0.538, 'neu': 0.462, 'pos': 0.0, 'compound': -0.5423}\n",
      "{'neg': 0.0, 'neu': 0.282, 'pos': 0.718, 'compound': 0.8807}\n",
      "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound': 0.3612}\n",
      "{'neg': 0.0, 'neu': 0.213, 'pos': 0.787, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.73, 'pos': 0.27, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}\n",
      "{'neg': 0.027, 'neu': 0.87, 'pos': 0.103, 'compound': 0.8555}\n",
      "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.093, 'pos': 0.907, 'compound': 0.8689}\n",
      "{'neg': 0.0, 'neu': 0.28, 'pos': 0.72, 'compound': 0.8271}\n",
      "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}\n",
      "{'neg': 0.058, 'neu': 0.879, 'pos': 0.064, 'compound': -0.1911}\n",
      "{'neg': 0.175, 'neu': 0.825, 'pos': 0.0, 'compound': -0.1779}\n",
      "{'neg': 0.043, 'neu': 0.863, 'pos': 0.093, 'compound': 0.8758}\n",
      "{'neg': 0.0, 'neu': 0.811, 'pos': 0.189, 'compound': 0.4215}\n",
      "{'neg': 0.138, 'neu': 0.862, 'pos': 0.0, 'compound': -0.4588}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.7184}\n",
      "{'neg': 0.0, 'neu': 0.896, 'pos': 0.104, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.362, 'neu': 0.638, 'pos': 0.0, 'compound': -0.3421}\n",
      "{'neg': 0.333, 'neu': 0.0, 'pos': 0.667, 'compound': 0.3182}\n",
      "{'neg': 0.039, 'neu': 0.91, 'pos': 0.051, 'compound': 0.0941}\n",
      "{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'compound': 0.9288}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.448, 'pos': 0.552, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.033, 'neu': 0.823, 'pos': 0.144, 'compound': 0.8625}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.826, 'pos': 0.174, 'compound': 0.7089}\n",
      "{'neg': 0.0, 'neu': 0.942, 'pos': 0.058, 'compound': 0.6908}\n",
      "{'neg': 0.0, 'neu': 0.506, 'pos': 0.494, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 0.902, 'pos': 0.098, 'compound': 0.6369}\n",
      "{'neg': 0.0, 'neu': 0.865, 'pos': 0.135, 'compound': 0.3612}\n",
      "{'neg': 0.0, 'neu': 0.368, 'pos': 0.632, 'compound': 0.8225}\n",
      "{'neg': 0.0, 'neu': 0.69, 'pos': 0.31, 'compound': 0.4019}\n",
      "{'neg': 0.0, 'neu': 0.459, 'pos': 0.541, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.737, 'pos': 0.263, 'compound': 0.3612}\n",
      "{'neg': 0.0, 'neu': 0.621, 'pos': 0.379, 'compound': 0.891}\n",
      "{'neg': 0.09, 'neu': 0.863, 'pos': 0.047, 'compound': -0.9542}\n",
      "{'neg': 0.0, 'neu': 0.51, 'pos': 0.49, 'compound': 0.5859}\n",
      "{'neg': 0.088, 'neu': 0.85, 'pos': 0.062, 'compound': -0.8658}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.13, 'neu': 0.82, 'pos': 0.05, 'compound': -0.97}\n",
      "{'neg': 0.012, 'neu': 0.811, 'pos': 0.177, 'compound': 0.9912}\n",
      "{'neg': 0.0, 'neu': 0.326, 'pos': 0.674, 'compound': 0.7351}\n",
      "{'neg': 0.094, 'neu': 0.791, 'pos': 0.114, 'compound': 0.2481}\n",
      "{'neg': 0.0, 'neu': 0.811, 'pos': 0.189, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.89, 'pos': 0.11, 'compound': 0.9001}\n",
      "{'neg': 0.026, 'neu': 0.859, 'pos': 0.116, 'compound': 0.9313}\n",
      "{'neg': 0.005, 'neu': 0.902, 'pos': 0.093, 'compound': 0.9648}\n",
      "{'neg': 0.0, 'neu': 0.734, 'pos': 0.266, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.441, 'pos': 0.559, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 0.631, 'pos': 0.369, 'compound': 0.6249}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.872, 'pos': 0.128, 'compound': 0.4173}\n",
      "{'neg': 0.0, 'neu': 0.203, 'pos': 0.797, 'compound': 0.8957}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.131, 'neu': 0.763, 'pos': 0.106, 'compound': -0.1531}\n",
      "{'neg': 0.0, 'neu': 0.253, 'pos': 0.747, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.7506}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.238, 'pos': 0.762, 'compound': 0.7506}\n",
      "{'neg': 0.0, 'neu': 0.244, 'pos': 0.756, 'compound': 0.4754}\n",
      "{'neg': 0.0, 'neu': 0.526, 'pos': 0.474, 'compound': 0.4019}\n",
      "{'neg': 0.0, 'neu': 0.455, 'pos': 0.545, 'compound': 0.8957}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.506, 'pos': 0.494, 'compound': 0.5994}\n",
      "{'neg': 0.082, 'neu': 0.859, 'pos': 0.059, 'compound': -0.8807}\n",
      "{'neg': 0.15, 'neu': 0.79, 'pos': 0.06, 'compound': -0.9955}\n",
      "{'neg': 0.224, 'neu': 0.728, 'pos': 0.048, 'compound': -0.9831}\n",
      "{'neg': 0.023, 'neu': 0.802, 'pos': 0.176, 'compound': 0.9964}\n",
      "{'neg': 0.0, 'neu': 0.674, 'pos': 0.326, 'compound': 0.891}\n",
      "{'neg': 0.0, 'neu': 0.253, 'pos': 0.747, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.9186}\n",
      "{'neg': 0.0, 'neu': 0.253, 'pos': 0.747, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 0.392, 'pos': 0.608, 'compound': 0.4767}\n",
      "{'neg': 0.0, 'neu': 0.886, 'pos': 0.114, 'compound': 0.743}\n",
      "{'neg': 0.0, 'neu': 0.772, 'pos': 0.228, 'compound': 0.9451}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.039, 'neu': 0.857, 'pos': 0.104, 'compound': 0.9472}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.058, 'neu': 0.818, 'pos': 0.124, 'compound': 0.991}\n",
      "{'neg': 0.0, 'neu': 0.896, 'pos': 0.104, 'compound': 0.2732}\n",
      "{'neg': 0.032, 'neu': 0.582, 'pos': 0.386, 'compound': 0.9643}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.012, 'neu': 0.811, 'pos': 0.177, 'compound': 0.9912}\n",
      "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.489, 'pos': 0.511, 'compound': 0.2716}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.717, 'pos': 0.283, 'compound': 0.9217}\n",
      "{'neg': 0.017, 'neu': 0.814, 'pos': 0.168, 'compound': 0.9442}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.505, 'pos': 0.495, 'compound': 0.7082}\n",
      "{'neg': 0.0, 'neu': 0.9, 'pos': 0.1, 'compound': 0.9544}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.061, 'neu': 0.84, 'pos': 0.099, 'compound': 0.8253}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.064, 'neu': 0.731, 'pos': 0.205, 'compound': 0.9905}\n",
      "{'neg': 0.0, 'neu': 0.562, 'pos': 0.438, 'compound': 0.5994}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.009, 'neu': 0.827, 'pos': 0.164, 'compound': 0.9934}\n",
      "{'neg': 0.0, 'neu': 0.408, 'pos': 0.592, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.035, 'neu': 0.845, 'pos': 0.119, 'compound': 0.8689}\n",
      "{'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.9001}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.122, 'neu': 0.627, 'pos': 0.251, 'compound': 0.5106}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.138, 'neu': 0.604, 'pos': 0.258, 'compound': 0.4215}\n",
      "{'neg': 0.276, 'neu': 0.488, 'pos': 0.236, 'compound': -0.126}\n",
      "{'neg': 0.106, 'neu': 0.703, 'pos': 0.191, 'compound': 0.9852}\n",
      "{'neg': 0.02, 'neu': 0.862, 'pos': 0.118, 'compound': 0.8484}\n",
      "{'neg': 0.0, 'neu': 0.449, 'pos': 0.551, 'compound': 0.926}\n",
      "{'neg': 0.049, 'neu': 0.631, 'pos': 0.32, 'compound': 0.9002}\n",
      "{'neg': 0.084, 'neu': 0.751, 'pos': 0.166, 'compound': 0.8127}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.337, 'neu': 0.435, 'pos': 0.228, 'compound': -0.25}\n",
      "{'neg': 0.0, 'neu': 0.556, 'pos': 0.444, 'compound': 0.4926}\n",
      "{'neg': 0.0, 'neu': 0.495, 'pos': 0.505, 'compound': 0.8481}\n",
      "{'neg': 0.121, 'neu': 0.605, 'pos': 0.274, 'compound': 0.4199}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.239, 'pos': 0.761, 'compound': 0.4926}\n",
      "{'neg': 0.0, 'neu': 0.603, 'pos': 0.397, 'compound': 0.7121}\n",
      "{'neg': 0.0, 'neu': 0.549, 'pos': 0.451, 'compound': 0.8885}\n",
      "{'neg': 0.0, 'neu': 0.247, 'pos': 0.753, 'compound': 0.7263}\n",
      "{'neg': 0.337, 'neu': 0.435, 'pos': 0.228, 'compound': -0.25}\n",
      "{'neg': 0.0, 'neu': 0.826, 'pos': 0.174, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.79, 'pos': 0.21, 'compound': 0.4927}\n",
      "{'neg': 0.0, 'neu': 0.515, 'pos': 0.485, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.455, 'pos': 0.545, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.45, 'pos': 0.55, 'compound': 0.7269}\n",
      "{'neg': 0.0, 'neu': 0.63, 'pos': 0.37, 'compound': 0.8037}\n",
      "{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.4215}\n",
      "{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.5574}\n",
      "{'neg': 0.0, 'neu': 0.72, 'pos': 0.28, 'compound': 0.6814}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.39, 'pos': 0.61, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.818, 'pos': 0.182, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.4927}\n",
      "{'neg': 0.0, 'neu': 0.62, 'pos': 0.38, 'compound': 0.471}\n",
      "{'neg': 0.0, 'neu': 0.615, 'pos': 0.385, 'compound': 0.3612}\n",
      "{'neg': 0.0, 'neu': 0.33, 'pos': 0.67, 'compound': 0.7263}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.14, 'neu': 0.56, 'pos': 0.3, 'compound': 0.5089}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.217, 'neu': 0.54, 'pos': 0.243, 'compound': 0.0757}\n",
      "{'neg': 0.0, 'neu': 0.38, 'pos': 0.62, 'compound': 0.7988}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.626, 'pos': 0.374, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.615, 'pos': 0.385, 'compound': 0.3612}\n",
      "{'neg': 0.0, 'neu': 0.346, 'pos': 0.654, 'compound': 0.5826}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.71, 'pos': 0.29, 'compound': 0.7879}\n",
      "{'neg': 0.063, 'neu': 0.822, 'pos': 0.116, 'compound': 0.2714}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.691, 'pos': 0.309, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.69, 'pos': 0.31, 'compound': 0.6696}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.503, 'pos': 0.497, 'compound': 0.6049}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.385, 'pos': 0.615, 'compound': 0.4926}\n",
      "{'neg': 0.0, 'neu': 0.635, 'pos': 0.365, 'compound': 0.3182}\n",
      "{'neg': 0.198, 'neu': 0.703, 'pos': 0.099, 'compound': -0.6705}\n",
      "{'neg': 0.289, 'neu': 0.579, 'pos': 0.132, 'compound': -0.4588}\n",
      "{'neg': 0.0, 'neu': 0.593, 'pos': 0.407, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 0.792, 'pos': 0.208, 'compound': 0.2732}\n",
      "{'neg': 0.07, 'neu': 0.797, 'pos': 0.133, 'compound': 0.9433}\n",
      "{'neg': 0.088, 'neu': 0.784, 'pos': 0.127, 'compound': 0.9676}\n",
      "{'neg': 0.0, 'neu': 0.351, 'pos': 0.649, 'compound': 0.8122}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.326, 'neu': 0.357, 'pos': 0.317, 'compound': -0.0516}\n",
      "{'neg': 0.087, 'neu': 0.723, 'pos': 0.19, 'compound': 0.9805}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 0.351, 'pos': 0.649, 'compound': 0.5719}\n",
      "{'neg': 0.166, 'neu': 0.527, 'pos': 0.307, 'compound': 0.4374}\n",
      "{'neg': 0.06, 'neu': 0.762, 'pos': 0.178, 'compound': 0.8943}\n",
      "{'neg': 0.257, 'neu': 0.631, 'pos': 0.112, 'compound': -0.4585}\n",
      "{'neg': 0.0, 'neu': 0.676, 'pos': 0.324, 'compound': 0.34}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.562, 'pos': 0.438, 'compound': 0.7783}\n",
      "{'neg': 0.089, 'neu': 0.771, 'pos': 0.14, 'compound': 0.8741}\n",
      "{'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.722, 'pos': 0.278, 'compound': 0.4019}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.463, 'pos': 0.537, 'compound': 0.7003}\n",
      "{'neg': 0.076, 'neu': 0.683, 'pos': 0.241, 'compound': 0.7614}\n",
      "{'neg': 0.62, 'neu': 0.38, 'pos': 0.0, 'compound': -0.5992}\n",
      "{'neg': 0.084, 'neu': 0.516, 'pos': 0.4, 'compound': 0.7089}\n",
      "{'neg': 0.0, 'neu': 0.43, 'pos': 0.57, 'compound': 0.6486}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.4939}\n",
      "{'neg': 0.0, 'neu': 0.464, 'pos': 0.536, 'compound': 0.5379}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.266, 'neu': 0.565, 'pos': 0.169, 'compound': -0.2942}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.4939}\n",
      "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.263, 'pos': 0.737, 'compound': 0.9049}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.39, 'pos': 0.61, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.593, 'pos': 0.407, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 0.547, 'pos': 0.453, 'compound': 0.8442}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.4404}\n",
      "{'neg': 0.203, 'neu': 0.589, 'pos': 0.209, 'compound': 0.024}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.116, 'neu': 0.478, 'pos': 0.406, 'compound': 0.818}\n",
      "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.543, 'pos': 0.457, 'compound': 0.4939}\n",
      "{'neg': 0.0, 'neu': 0.408, 'pos': 0.592, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.672, 'pos': 0.328, 'compound': 0.5267}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.4939}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.582, 'pos': 0.418, 'compound': 0.7845}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.247, 'pos': 0.753, 'compound': 0.7269}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.125, 'neu': 0.62, 'pos': 0.255, 'compound': 0.8225}\n",
      "{'neg': 0.0, 'neu': 0.463, 'pos': 0.537, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.197, 'neu': 0.542, 'pos': 0.261, 'compound': 0.3182}\n",
      "{'neg': 0.0, 'neu': 0.593, 'pos': 0.407, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.37, 'pos': 0.63, 'compound': 0.6249}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.633, 'pos': 0.367, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.658, 'pos': 0.342, 'compound': 0.3818}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.472, 'pos': 0.528, 'compound': 0.68}\n",
      "{'neg': 0.0, 'neu': 0.556, 'pos': 0.444, 'compound': 0.4927}\n",
      "{'neg': 0.0, 'neu': 0.654, 'pos': 0.346, 'compound': 0.9514}\n",
      "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.674, 'pos': 0.326, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.704, 'pos': 0.296, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.5, 'pos': 0.5, 'compound': 0.8399}\n",
      "{'neg': 0.0, 'neu': 0.565, 'pos': 0.435, 'compound': 0.7717}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.697, 'pos': 0.303, 'compound': 0.7263}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.455, 'pos': 0.545, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.226, 'pos': 0.774, 'compound': 0.8822}\n",
      "{'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.4927}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.633, 'pos': 0.367, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.177, 'neu': 0.663, 'pos': 0.16, 'compound': -0.0772}\n",
      "{'neg': 0.0, 'neu': 0.626, 'pos': 0.374, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.37, 'pos': 0.63, 'compound': 0.6249}\n",
      "{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.299, 'pos': 0.701, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.16, 'neu': 0.715, 'pos': 0.125, 'compound': -0.1984}\n",
      "{'neg': 0.415, 'neu': 0.325, 'pos': 0.26, 'compound': -0.228}\n",
      "{'neg': 0.0, 'neu': 0.282, 'pos': 0.718, 'compound': 0.6249}\n",
      "{'neg': 0.0, 'neu': 0.253, 'pos': 0.747, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 0.61, 'pos': 0.39, 'compound': 0.4927}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.239, 'pos': 0.761, 'compound': 0.7494}\n",
      "{'neg': 0.0, 'neu': 0.519, 'pos': 0.481, 'compound': 0.4019}\n",
      "{'neg': 0.0, 'neu': 0.159, 'pos': 0.841, 'compound': 0.6486}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.537, 'pos': 0.463, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.455, 'pos': 0.545, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.7003}\n",
      "{'neg': 0.063, 'neu': 0.692, 'pos': 0.245, 'compound': 0.7179}\n",
      "{'neg': 0.0, 'neu': 0.455, 'pos': 0.545, 'compound': 0.3382}\n",
      "{'neg': 0.17, 'neu': 0.714, 'pos': 0.115, 'compound': -0.25}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.715, 'pos': 0.285, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 0.699, 'pos': 0.301, 'compound': 0.7096}\n",
      "{'neg': 0.0, 'neu': 0.282, 'pos': 0.718, 'compound': 0.6249}\n",
      "{'neg': 0.113, 'neu': 0.546, 'pos': 0.341, 'compound': 0.9112}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.7184}\n",
      "{'neg': 0.0, 'neu': 0.469, 'pos': 0.531, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.704, 'pos': 0.296, 'compound': 0.4939}\n",
      "{'neg': 0.277, 'neu': 0.536, 'pos': 0.188, 'compound': -0.25}\n",
      "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.542, 'pos': 0.458, 'compound': 0.765}\n",
      "{'neg': 0.171, 'neu': 0.443, 'pos': 0.386, 'compound': 0.5255}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.385, 'pos': 0.615, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.5859}\n",
      "{'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.4927}\n",
      "{'neg': 0.0, 'neu': 0.202, 'pos': 0.798, 'compound': 0.7845}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.4927}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.4939}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.741, 'pos': 0.259, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.455, 'pos': 0.545, 'compound': 0.3382}\n",
      "{'neg': 0.039, 'neu': 0.419, 'pos': 0.541, 'compound': 0.9855}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.7003}\n",
      "{'neg': 0.486, 'neu': 0.362, 'pos': 0.152, 'compound': -0.6808}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.247, 'pos': 0.753, 'compound': 0.7269}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.46, 'pos': 0.54, 'compound': 0.5707}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.175, 'pos': 0.825, 'compound': 0.5719}\n",
      "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.254, 'neu': 0.328, 'pos': 0.418, 'compound': 0.25}\n",
      "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.512, 'pos': 0.488, 'compound': 0.8221}\n",
      "{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'compound': 0.7003}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.408, 'pos': 0.592, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.488, 'pos': 0.512, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.4927}\n",
      "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.562, 'pos': 0.438, 'compound': 0.7783}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.4939}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 0.476, 'pos': 0.524, 'compound': 0.8316}\n",
      "{'neg': 0.0, 'neu': 0.455, 'pos': 0.545, 'compound': 0.3382}\n",
      "{'neg': 0.0, 'neu': 0.538, 'pos': 0.462, 'compound': 0.6474}\n",
      "{'neg': 0.0, 'neu': 0.649, 'pos': 0.351, 'compound': 0.4019}\n"
     ]
    }
   ],
   "source": [
    "column_name = 'text'\n",
    "\n",
    "# Load your DataFrame here\n",
    "# df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Extract the column from the DataFrame\n",
    "sentences = df[column_name]\n",
    "\n",
    "# Iterate through each sentence in the column and analyze its sentiment\n",
    "for sentence in sentences:\n",
    "    ss = sid.polarity_scores(sentence) \n",
    "    print(ss)\n",
    "\n",
    "\n",
    "\n",
    "#OBS, cant deal with NA's, try deleting all rows that are NA in text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c189f5e-a93b-4433-b11a-2bef601f1045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186fda1-72dd-4e42-ae8c-0ac5450ca456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e30d66-d813-45ba-92f0-0f3af242db60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51a2a018-2c3e-43a7-bb7b-2b8b5cab0ec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2506407580.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[38], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    for i, row in df.iterrows(), total=len(df):\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import FloatProgress\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "res = {}\n",
    "for i, row in df.iterrows(), total=len(df):\n",
    "    text = row['text']\n",
    "    myid = row['unique_ID']\n",
    "    res[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d2c65a2-65a8-4f0c-a189-0c71e1d9e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x16e69ba60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/notebook.py\", line 278, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x16e69ba60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/notebook.py\", line 278, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x16e69ba60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/notebook.py\", line 278, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x16e69ba60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/notebook.py\", line 278, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x16e69ba60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/notebook.py\", line 278, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "quote_from_bytes() expected bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m myid \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m res[myid] \u001b[38;5;241m=\u001b[39m \u001b[43msia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/vaderSentiment/vaderSentiment.py:240\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolarity_scores\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    Return a float for sentiment strength based on the input text.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    Positive values are positive valence, negative value are negative\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    valence.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mTranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# convert emojis to their textual descriptions\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     text_no_emoji \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/translatte/translatte.py:27\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[0;34m(input_text, target_lang, source_lang)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate\u001b[39m(input_text, target_lang, source_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 27\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://translate.googleapis.com/translate_a/single?client=gtx&sl=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource_lang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&tl=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_lang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&dt=t&q=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mquote\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m     response \u001b[38;5;241m=\u001b[39m Translator\u001b[38;5;241m.\u001b[39mget_response_from_request(Request(url\u001b[38;5;241m=\u001b[39murl))\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Translator\u001b[38;5;241m.\u001b[39mget_translation_from_response(response)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/parse.py:893\u001b[0m, in \u001b[0;36mquote\u001b[0;34m(string, safe, encoding, errors)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquote() doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 893\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquote_from_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/urllib/parse.py:923\u001b[0m, in \u001b[0;36mquote_from_bytes\u001b[0;34m(bs, safe)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Like quote(), but accepts a bytes object rather than a str, and does\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;124;03mnot perform string-to-bytes encoding.  It always returns an ASCII string.\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;124;03mquote_from_bytes(b'abc def\\x3f') -> 'abc%20def%3f'\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bs, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[0;32m--> 923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquote_from_bytes() expected bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m bs:\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: quote_from_bytes() expected bytes"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    myid = row['unique_ID']\n",
    "    res[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335009e1-1c67-40d2-8d4e-da1a9114cedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a73617a9-a671-43a1-ba37-e981b0d62dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pîroz be\n"
     ]
    }
   ],
   "source": [
    "example = df['text'][50]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f41c6a-6ec1-45a2-bb29-a7a7d4f75042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d59e15b0-0b15-4360-8c1b-c37df32b9eb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/idahelenedencker/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tokens[:\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m     ]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/idahelenedencker/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(example)\n",
    "tokens[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a29018-b7f2-48a5-a4df-0f206879bcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c5a98e-f002-4eef-9c1e-6524374b48d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading SentimentIntensityAnalyzer: <urlopen error\n",
      "[nltk_data]     [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify\n",
      "[nltk_data]     failed: unable to get local issuer certificate\n",
      "[nltk_data]     (_ssl.c:1006)>\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - '/Users/idahelenedencker/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 6\u001b[0m sia \u001b[38;5;241m=\u001b[39m \u001b[43mSentimentIntensityAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/sentiment/vader.py:340\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.__init__\u001b[0;34m(self, lexicon_file)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    338\u001b[0m     lexicon_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    339\u001b[0m ):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon_file \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexicon_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_lex_dict()\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstants \u001b[38;5;241m=\u001b[39m VaderConstants()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - '/Users/idahelenedencker/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "nltk.download('SentimentIntensityAnalyzer')\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625558d9-4aef-4cd6-8e20-fd18ffef4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109cf88-71dc-459b-86d1-045c662c36fc",
   "metadata": {},
   "source": [
    "### Transformer (Roberta)\n",
    "\n",
    "Nlp model that can take realtion of words into account "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e38f9918-66d3-4536-9190-7106a0f326e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.11.3)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scipy) (1.23.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cdee3b6-8af5-4139-9ec4-62664f330b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05e2c2c5-a84e-4e05-8628-feab1cb6b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "be7830cc-fcce-4d04-ab7e-0e9c948f871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|█████████████████| 747/747 [00:00<00:00, 1.28MB/s]\n",
      "Downloading vocab.json: 100%|████████████████| 899k/899k [00:00<00:00, 2.45MB/s]\n",
      "Downloading merges.txt: 100%|████████████████| 456k/456k [00:00<00:00, 5.00MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████| 150/150 [00:00<00:00, 327kB/s]\n",
      "Exception ignored in: <function tqdm.__del__ at 0x16e69ba60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/notebook.py\", line 278, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x16e69ba60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py\", line 1149, in __del__\n",
      "    self.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/notebook.py\", line 278, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n",
      "Downloading pytorch_model.bin: 100%|█████████| 499M/499M [00:17<00:00, 27.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "257d3e9f-ca23-4ee1-a1c9-eff7d21eba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pîroz be\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.204, 'pos': 0.796, 'compound': 0.5994}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VADER results on example\n",
    "print(example)\n",
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "94ddb610-21a1-4c4e-aeb2-d3019b1cd0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.12730502, 'roberta_neu': 0.6950272, 'roberta_pos': 0.17766786}\n"
     ]
    }
   ],
   "source": [
    "# Run for Roberta Model\n",
    "encoded_text = tokenizer(example, return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg' : scores[0],\n",
    "    'roberta_neu' : scores[1],\n",
    "    'roberta_pos' : scores[2]\n",
    "}\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "39ef003b-fb55-4af5-a44d-956e0be225b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg' : scores[0],\n",
    "        'roberta_neu' : scores[1],\n",
    "        'roberta_pos' : scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6fed53ca-ca69-4f2d-8619-fd610a42fc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_ID</th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>file_name</th>\n",
       "      <th>main_post</th>\n",
       "      <th>name_abbreviation</th>\n",
       "      <th>offentlig_privat</th>\n",
       "      <th>date_post</th>\n",
       "      <th>n_post_day</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>has_comments</th>\n",
       "      <th>total_n_comments</th>\n",
       "      <th>n_total_reactions</th>\n",
       "      <th>count_like</th>\n",
       "      <th>count_heart</th>\n",
       "      <th>count_haha</th>\n",
       "      <th>count_care</th>\n",
       "      <th>count_angry</th>\n",
       "      <th>count_sad</th>\n",
       "      <th>count_wow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>YiYiP-3005-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>3005</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>YiYiP-2905-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2905</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1599</td>\n",
       "      <td>YiYiP-2806-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2806</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1599</td>\n",
       "      <td>YiYiP-2806-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2806</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1598</td>\n",
       "      <td>YiYiP-2705-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2705</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1597</td>\n",
       "      <td>YiYiP-2506-2_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1597</td>\n",
       "      <td>YiYiP-2506-2_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>1</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>1596</td>\n",
       "      <td>YiYiP-2506-1_slut.json</td>\n",
       "      <td>0</td>\n",
       "      <td>YiYi</td>\n",
       "      <td>P</td>\n",
       "      <td>2506</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_ID  index    ID               file_name  main_post  \\\n",
       "0           1      0  1601  YiYiP-3005-1_slut.json          1   \n",
       "1           2      1  1600  YiYiP-2905-1_slut.json          1   \n",
       "2           3      2  1599  YiYiP-2806-1_slut.json          1   \n",
       "3           4      3  1599  YiYiP-2806-1_slut.json          0   \n",
       "4           5      4  1598  YiYiP-2705-1_slut.json          1   \n",
       "5           6      5  1597  YiYiP-2506-2_slut.json          1   \n",
       "6           7      6  1597  YiYiP-2506-2_slut.json          0   \n",
       "7           8      7  1596  YiYiP-2506-1_slut.json          1   \n",
       "8           9      8  1596  YiYiP-2506-1_slut.json          0   \n",
       "9          10      9  1596  YiYiP-2506-1_slut.json          0   \n",
       "10         11     10  1596  YiYiP-2506-1_slut.json          0   \n",
       "11         12     11  1596  YiYiP-2506-1_slut.json          0   \n",
       "12         13     12  1596  YiYiP-2506-1_slut.json          0   \n",
       "13         14     13  1596  YiYiP-2506-1_slut.json          0   \n",
       "14         15     14  1596  YiYiP-2506-1_slut.json          0   \n",
       "15         16     15  1596  YiYiP-2506-1_slut.json          0   \n",
       "16         17     16  1596  YiYiP-2506-1_slut.json          0   \n",
       "17         18     17  1596  YiYiP-2506-1_slut.json          0   \n",
       "18         19     18  1596  YiYiP-2506-1_slut.json          0   \n",
       "19         20     19  1596  YiYiP-2506-1_slut.json          0   \n",
       "\n",
       "   name_abbreviation offentlig_privat  date_post  n_post_day  week  ...  \\\n",
       "0               YiYi                P       3005           1     5  ...   \n",
       "1               YiYi                P       2905           1     5  ...   \n",
       "2               YiYi                P       2806           1     9  ...   \n",
       "3               YiYi                P       2806           1     9  ...   \n",
       "4               YiYi                P       2705           1     4  ...   \n",
       "5               YiYi                P       2506           2     8  ...   \n",
       "6               YiYi                P       2506           2     8  ...   \n",
       "7               YiYi                P       2506           1     8  ...   \n",
       "8               YiYi                P       2506           1     8  ...   \n",
       "9               YiYi                P       2506           1     8  ...   \n",
       "10              YiYi                P       2506           1     8  ...   \n",
       "11              YiYi                P       2506           1     8  ...   \n",
       "12              YiYi                P       2506           1     8  ...   \n",
       "13              YiYi                P       2506           1     8  ...   \n",
       "14              YiYi                P       2506           1     8  ...   \n",
       "15              YiYi                P       2506           1     8  ...   \n",
       "16              YiYi                P       2506           1     8  ...   \n",
       "17              YiYi                P       2506           1     8  ...   \n",
       "18              YiYi                P       2506           1     8  ...   \n",
       "19              YiYi                P       2506           1     8  ...   \n",
       "\n",
       "   has_comments total_n_comments n_total_reactions count_like count_heart  \\\n",
       "0             0                0                25         22           3   \n",
       "1             0                0                34         32           2   \n",
       "2             1                1                31         29           2   \n",
       "3             1                1                 1          1           0   \n",
       "4             0                0                11         11           0   \n",
       "5             1                1                32         23           0   \n",
       "6             1                1                 1          1           0   \n",
       "7             1               37               127        127           0   \n",
       "8             1               37                 1          1           0   \n",
       "9             1               37                 1          1           0   \n",
       "10            1               37                 1          1           0   \n",
       "11            1               37                 1          1           0   \n",
       "12            1               37                 1          1           0   \n",
       "13            1               37                 1          1           0   \n",
       "14            1               37                 1          1           0   \n",
       "15            1               37                 1          1           0   \n",
       "16            1               37                 1          1           0   \n",
       "17            1               37                 1          1           0   \n",
       "18            1               37                 1          1           0   \n",
       "19            1               37                 1          1           0   \n",
       "\n",
       "    count_haha  count_care count_angry  count_sad count_wow  \n",
       "0            0           0           0          0         0  \n",
       "1            0           0           0          0         0  \n",
       "2            0           0           0          0         0  \n",
       "3            0           0           0          0         0  \n",
       "4            0           0           0          0         0  \n",
       "5            0           0           0          9         0  \n",
       "6            0           0           0          0         0  \n",
       "7            0           0           0          0         0  \n",
       "8            0           0           0          0         0  \n",
       "9            0           0           0          0         0  \n",
       "10           0           0           0          0         0  \n",
       "11           0           0           0          0         0  \n",
       "12           0           0           0          0         0  \n",
       "13           0           0           0          0         0  \n",
       "14           0           0           0          0         0  \n",
       "15           0           0           0          0         0  \n",
       "16           0           0           0          0         0  \n",
       "17           0           0           0          0         0  \n",
       "18           0           0           0          0         0  \n",
       "19           0           0           0          0         0  \n",
       "\n",
       "[20 rows x 34 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae119a8b-5559-4513-83e0-738fb57492bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m res \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m         text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/notebook.py:233\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    232\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        text = row['text']\n",
    "        myid = row['unique_ID']\n",
    "        #vader_result = sia.polarity_scores(text)\n",
    "        #vader_result_rename = {}\n",
    "        #for key, value in vader_result.items():\n",
    "            #vader_result_rename[f\"vader_{key}\"] = value\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        #both = {**vader_result_rename, **roberta_result}\n",
    "        res[myid] = roberta_result\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1edf4a0b-50ad-4190-ada8-ff00bb5a61f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m     myid \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m     roberta_result \u001b[38;5;241m=\u001b[39m \u001b[43mpolarity_scores_roberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     res[myid] \u001b[38;5;241m=\u001b[39m roberta_result\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[76], line 2\u001b[0m, in \u001b[0;36mpolarity_scores_roberta\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolarity_scores_roberta\u001b[39m(example):\n\u001b[0;32m----> 2\u001b[0m     encoded_text \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_text)\n\u001b[1;32m      4\u001b[0m     scores \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2790\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2788\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2790\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2792\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2848\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2848\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2850\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2851\u001b[0m     )\n\u001b[1;32m   2853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2855\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2857\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        text = row['text']\n",
    "        myid = row['unique_ID']\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        res[myid] = roberta_result\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c80fa-58b7-4a99-b037-e8990d9cd19d",
   "metadata": {},
   "source": [
    "## multilevel modelling (predictive modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e902022f-2931-451b-b796-2ae806418961",
   "metadata": {},
   "source": [
    "contrast: intervention Across all posts (i.e. comparing posts that have the intervention to posts that don’t have the intervention) – obviously we need to be careful here about the nestedness of these observations (posts nested in politicians, and potentially politicians nested in kommuner – but probably our data isn’t sufficient for such models to converge)\n",
    "\n",
    "To account for nestedness, do random and fixed effects on e.g. 'politician', 'kommune'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27757230-65fb-4b8f-b50d-8ff0fe4ab92e",
   "metadata": {},
   "source": [
    "# Machine learning "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
