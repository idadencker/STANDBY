p3 <- ggplot(sentiment_data, aes(x = intervention, y = neg_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "salmon", color = "black") +
labs(title = "Negative") +
theme_minimal()
# Plotting compound scores
p4 <- ggplot(sentiment_data, aes(x = intervention, y = compound_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgrey", color = "black") +
labs(title = "Compound") +
theme_minimal()
# Combining plots
plot_grid(p1, p2, p3, p4, ncol = 1, align = "v")
# Combining plots
grid.arrange(p1, p2, p3, p4, ncol = 1)
p4
# Combining plots
grid.arrange(p1, p2, p3, p4, ncol = 2)
#simple model 2
simple_model_2 <- glmer(intervention ~ compound + (1| ID), data = sentiment_data, family = binomial)
#log odds of intervention is predicted by compound score (fixed effect) allowing the model to vary by politician
summary(simple_model_2)
#log odds of intervention is predicted by compound score (fixed effect) allowing the model to vary by municipality
summary(simple_model)
#no mixed effects model
no_mixed_model <- glm(intervention ~ compound,family=binomial(link='logit'),data=sentiment_data)
summary(no_mixed_model)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, lme4)
pacman::p_load(tidyverse, lme4)
#load in data
sentiment_data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/vaders_roberta_bert.csv')
#can check number of distinct values for a column
n_distinct(sentiment_data$name_abbreviation)
#check class of every column
sapply(sentiment_data, class)
#factorize data
# data that cant be 'integer' numbers and have levels are transformed, e.g we can't have 7,3 weeks or 1,2 municipality == transformed
sentiment_data <- sentiment_data %>%
mutate(
intervention = as.factor(intervention),
main_post = as.factor(main_post),
week = as.factor(week),
subcomment = as.factor(subcomment),
municipality = as.factor(municipality),
offentlig_privat = as.factor(offentlig_privat),
roberta_label = as.factor(roberta_label),
name_abbreviation = as.factor(name_abbreviation)
)
#check the levels look right
sapply(sentiment_data, levels)
#can check the number of levels for a factor column
nlevels(sentiment_data$name_abbreviation)
library(ggplot2)
library(gridExtra)
# Plotting positive scores
p1 <- ggplot(sentiment_data, aes(x = intervention, y = pos_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "skyblue", color = "black") +
labs(title = "Positive") +
theme_minimal()
# Plotting neutral scores
p2 <- ggplot(sentiment_data, aes(x = intervention, y = neu_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgreen", color = "black") +
labs(title = "Neutral") +
theme_minimal()
# Plotting negative scores
p3 <- ggplot(sentiment_data, aes(x = intervention, y = neg_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "salmon", color = "black") +
labs(title = "Negative") +
theme_minimal()
# Plotting compound scores
p4 <- ggplot(sentiment_data, aes(x = intervention, y = compound_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgrey", color = "black") +
labs(title = "Compound") +
theme_minimal()
# Combining plots
grid.arrange(p1, p2, p3, p4, ncol = 2)
#looking here we see that when the intervention is yes the comments are generally more negative (lower pos score + higher neg score + lower compound score). This is good to know when starting to model the effect of intervention. So looking at this, we expect that an intervention (intervention==yes) will entail a more negative sentiment in comments compared to no intervention (intercention == no)
library(ggplot2)
library(gridExtra)
# Plotting positive scores
p1 <- ggplot(sentiment_data, aes(x = intervention, y = pos_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "skyblue", color = "black") +
labs(title = "Positive") +
theme_minimal()
# Plotting neutral scores
p2 <- ggplot(sentiment_data, aes(x = intervention, y = neu_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgreen", color = "black") +
labs(title = "Neutral") +
theme_minimal()
# Plotting negative scores
p3 <- ggplot(sentiment_data, aes(x = intervention, y = neg_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "salmon", color = "black") +
labs(title = "Negative") +
theme_minimal()
# Plotting compound scores
p4 <- ggplot(sentiment_data, aes(x = intervention, y = compound_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgrey", color = "black") +
labs(title = "Compound") +
theme_minimal()
# Combining plots
grid.arrange(p1, p2, p3, p4, ncol = 2)
#looking here we see that when the intervention is yes the comments are generally more negative (lower pos score + higher neg score + lower compound score). This is good to know when starting to model the effect of intervention. So looking at this, we expect that an intervention (intervention==yes) will entail a more negative sentiment in comments compared to no intervention (intercention == no)
#test lme4 is working
model <- lmer(pos_score_roberta ~ roberta_label + (1 | municipality), data=sentiment_data)
model
summary(model)
#simple plotting
plot(pos_score_roberta ~ neg_score_roberta, data = sentiment_data, main = "pos_score_roberta ~ neg_score_roberta")
#First: check level of the outcome variable
levels(sentiment_data$intervention)
#no mixed effects model
no_mixed_model <- glm(intervention ~ compound,family=binomial(link='logit'),data=sentiment_data)
View(sentiment_data)
#no mixed effects model
no_mixed_model <- glm(intervention ~ compound,family=binomial(link='logit'),data=sentiment_data)
summary(no_mixed_model)
#no mixed effects model
no_mixed_model <- glm(intervention ~ compound_roberta,family=binomial(link='logit'),data=sentiment_data)
#simple model
# in logistic regression coefficients are a on log-oods scale = positive means increase in possibility
simple_model <- glmer(intervention ~ compound_roberta + (1| municipality), data = sentiment_data, family = binomial)
#log odds of intervention is predicted by compound score (fixed effect) allowing the model to vary by municipality
summary(simple_model)
#Below are the commands to run an empty model, that is, a model containing no predictors,
# and calculate the intraclass correlation coefficient (ICC; the degree of homogeneity of the outcome within clusters).
empty_model <- glmer(intervention ~ ( 1 | name_abbreviation), data=sentiment_data, family = "binomial")
#Below are the commands to run an empty model, that is, a model containing no predictors,
# and calculate the intraclass correlation coefficient (ICC; the degree of homogeneity of the outcome within clusters).
empty_model <- glmer(intervention ~ ( 1 | name_abbreviation), data=sentiment_data, family = "binomial")
summary(empty_model)
icc <- empty_model@theta[1]^2/ (empty_model@theta[1]^2 + (3.14159^2/3))
icc <- empty_model@theta[1]^2/ (empty_model@theta[1]^2 + (3.14159^2/3))
icc
var_components <- getVarCov(empty_model)
library(lme4)
var_components <- getVarCov(empty_model)
library(nlme)
var_components <- getVarCov(empty_model)
VarCorr(empty_model)
library(psychometric)
pacman::p_load(psychometric)
ICC1.lme(intervention, intervention, sentiment_data)
#Below are the commands to run an empty model, that is, a model containing no predictors,
# and calculate the intraclass correlation coefficient (ICC; the degree of homogeneity of the outcome within clusters).
empty_model <- glmer(intervention ~ ( 1 | name_abbreviation), data=sentiment_data, family = "binomial")
#Below are the commands to run an empty model, that is, a model containing no predictors,
# and calculate the intraclass correlation coefficient (ICC; the degree of homogeneity of the outcome within clusters).
empty_model <- glmer(intervention ~ ( 1 | name_abbreviation), data=sentiment_data, family = "binomial")
summary(empty_model)
ICC1.lme(intervention, name_abbreviation, sentiment_data)
VarCorr(empty_model)
ICC1.lme(intervention, name_abbreviation, sentiment_data)
colSums(is.na(sentiment_data))
ICC1.lme(intervention, name_abbreviation, sentiment_data)
empty_model@theta[1]
summary(empty_model)
icc
#no mixed effects model
no_mixed_model <- glm(intervention ~ compound_roberta,family=binomial(link='logit'),data=sentiment_data)
summary(no_mixed_model)
#can check number of distinct values for a column
n_distinct(sentiment_data$IS)
#can check number of distinct values for a column
n_distinct(sentiment_data$ID)
#Below are the commands to run an empty model, that is, a model containing no predictors,
# and calculate the intraclass correlation coefficient (ICC; the degree of homogeneity of the outcome within clusters).
empty_model <- glmer(intervention ~ ( 1 | ID), data=sentiment_data, family = "binomial")
summary(empty_model)
## 2-LEVEL MODEL (Comments nested in ID)
two_level_model <- glmer(intervention ~ compound_roberta + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model)
## 3-LEVEL MODEL (comments nested in ID nested in politicians)
three_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation), data = sentiment_data, family = binomial)
summary(three_level_model)
## 4-LEVEL MODEL (comments nested in ID nested in politicians nested in municipality)
four_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation/muncipality), data = sentiment_data, family = binomial)
## 4-LEVEL MODEL (comments nested in ID nested in politicians nested in municipality)
four_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation/municipality), data = sentiment_data, family = binomial)
summary(four_level_model)
#a model with separate random intercepts for each grouping variable without explicitly specifying the nesting. This is assuming that the grouping variables are independent of each other.
no_hier_model <- glmer(intervention ~ compound_roberta + (1| ID) + (1| name_abbreviation) + (1| municipality), data = sentiment_data, family = binomial)
summary(no_hier_model)
## 2-LEVEL MODEL (Comments nested in ID):
two_level_model <- glmer(intervention ~ compound_roberta + (1| ID), data = sentiment_data, family = binomial)
## 2-LEVEL MODEL (Comments nested in ID):
two_level_model <- glmer(intervention ~ compound_roberta + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model)
summary(two_level_model)
summary(no_mixed_model)
df_performance <- rbind(
performance::model_performance(empty_model, metrics= "common"),
performance::model_performance(no_mixed_model, metrics= "common"),
performance::model_performance(two_level_model, metrics= "common"),
performance::model_performance(three_level_model, metrics= "common"),
performance::model_performance(four_level_model, metrics= "common"),
performance::model_performance(no_hier_model, metrics= "common")) %>%
data.frame() %>%
rownames_to_column("models")
library(performance)
pacman::p_load(performance)
pacman::p_load(performance)
df_performance <- rbind(
performance::model_performance(empty_model, metrics= "common"),
performance::model_performance(no_mixed_model, metrics= "common"),
performance::model_performance(two_level_model, metrics= "common"),
performance::model_performance(three_level_model, metrics= "common"),
performance::model_performance(four_level_model, metrics= "common"),
performance::model_performance(no_hier_model, metrics= "common")) %>%
data.frame() %>%
rownames_to_column("models")
df_performance <- rbind(
performance::model_performance(empty_model, metrics= "common"),
#performance::model_performance(no_mixed_model, metrics= "common"),
performance::model_performance(two_level_model, metrics= "common"),
performance::model_performance(three_level_model, metrics= "common"),
performance::model_performance(four_level_model, metrics= "common"),
performance::model_performance(no_hier_model, metrics= "common")) %>%
data.frame() %>%
rownames_to_column("models")
df_performance <- rbind(
#performance::model_performance(empty_model, metrics= "common"),
#performance::model_performance(no_mixed_model, metrics= "common"),
performance::model_performance(two_level_model, metrics= "common"),
performance::model_performance(three_level_model, metrics= "common"),
performance::model_performance(four_level_model, metrics= "common"),
performance::model_performance(no_hier_model, metrics= "common")) %>%
data.frame() %>%
rownames_to_column("models")
#compare the different models like this:
f4 <- performance::model_performance(empty_model, metrics= "common")
View(f4)
f2 <- performance::model_performance(no_mixed_model, metrics= "common")
View(f2)
f3 <- performance::model_performance(two_level_model, metrics= "common")
f4 <- performance::model_performance(three_level_model, metrics= "common")
View(f4)
f5 <- performance::model_performance(four_level_model, metrics= "common")
f6 <- performance::model_performance(no_hier_model, metrics= "common")
f1 <- performance::model_performance(empty_model, metrics= "common")
f2 <- performance::model_performance(no_mixed_model, metrics= "common")
f3 <- performance::model_performance(two_level_model, metrics= "common")
f4 <- performance::model_performance(three_level_model, metrics= "common")
f5 <- performance::model_performance(four_level_model, metrics= "common")
f6 <- performance::model_performance(no_hier_model, metrics= "common")
f1
f2
print("model 1:")f1
print("model 1:")
print("model 1:")
f1
print("empty_model:")
f1
print("no_mixed_model:")
f2
print("two_level_model:")
f3
print("three_level_model:")
f4
print("four_level_model:")
f5
print("no_hier_model:")
f6
summary(no_hier_model)
knitr::opts_chunk$set(echo = TRUE)
#load in data
sentiment_data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/Sentiment CSV files/5_types_sen')
pacman::p_load(tidyverse, lme4)
#load in data
sentiment_data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/Sentiment CSV files/5_types_sen')
#load in data
sentiment_data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/Sentiment CSV files/5_types_sen.csv')
#can check number of distinct values for a column
n_distinct(sentiment_data$ID)
View(sentiment_data)
#check class of every column
sapply(sentiment_data, class)
#factorize data
# data that cant be 'integer' numbers and have levels are transformed, e.g we can't have 7,3 weeks or 1,2 municipality == transformed
sentiment_data <- sentiment_data %>%
mutate(
intervention = as.factor(intervention),
main_post = as.factor(main_post),
week = as.factor(week),
subcomment = as.factor(subcomment),
municipality = as.factor(municipality),
offentlig_privat = as.factor(offentlig_privat),
roberta_label = as.factor(roberta_label),
name_abbreviation = as.factor(name_abbreviation)
)
#check the levels look right
sapply(sentiment_data, levels)
#can check the number of levels for a factor column
nlevels(sentiment_data$name_abbreviation)
library(ggplot2)
library(gridExtra)
# Plotting positive scores
p1 <- ggplot(sentiment_data, aes(x = intervention, y = pos_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "skyblue", color = "black") +
labs(title = "Positive") +
theme_minimal()
# Plotting neutral scores
p2 <- ggplot(sentiment_data, aes(x = intervention, y = neu_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgreen", color = "black") +
labs(title = "Neutral") +
theme_minimal()
# Plotting negative scores
p3 <- ggplot(sentiment_data, aes(x = intervention, y = neg_score_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "salmon", color = "black") +
labs(title = "Negative") +
theme_minimal()
# Plotting compound scores
p4 <- ggplot(sentiment_data, aes(x = intervention, y = compound_roberta)) +
geom_bar(stat = "summary", fun = "mean", fill = "lightgrey", color = "black") +
labs(title = "Compound") +
theme_minimal()
# Combining plots
grid.arrange(p1, p2, p3, p4, ncol = 2)
#looking here we see that when the intervention is yes the comments are generally more negative (lower pos score + higher neg score + lower compound score). This is good to know before starting to model the effect of intervention. So looking at this, we expect that an intervention (intervention==yes) will entail a more negative sentiment in comments compared to no intervention (intervention == no)
#First: check level of the outcome variable
levels(sentiment_data$intervention)
#remember that in logistic regression coefficients are a on log-oods scale = positive means increase in possibility
##log odds of intervention is predicted by compound score (fixed effect) allowing the model to vary by group
##INTERCEPT ONLY MODEL:
#Below are the commands to run an empty model, that is, a model containing no predictors,
# and calculate the intraclass correlation coefficient (ICC; the degree of homogeneity of the outcome within clusters).
empty_model <- glmer(intervention ~ ( 1 | ID), data=sentiment_data, family = "binomial")
summary(empty_model)
#The random intercept variance (i.e., the level-2 residual) is in the "Random effects" part of the output: classes (Intercept) 115.2;
#The ICC represents the proportion of group-level variance to total variance.
icc <- empty_model@theta[1]^2/ (empty_model@theta[1]^2 + (3.14159^2/3))
icc #0.97
#This indicates that 97% of the chance of intervention is explained by between-classroom differences
## SIMPLE LOGISTIC REGRESSION MODEL (no mixed effects):
#no mixed effects model
no_mixed_model <- glm(intervention ~ compound_roberta,family=binomial(link='logit'),data=sentiment_data)
summary(no_mixed_model)
#no random effects: assume all data are independent from each other (not the case here)
#when the compound score increase with 1 (more positive sentiment) the log odds of the intervention being yes decreases with -0.59, i.e. more positive sentiment entails a lower probability of the intervention being yes, in accordance with what the plots above are showing. The predictor is siggnificant here.
## 2-LEVEL MODEL (Comments nested in ID):
two_level_model <- glmer(intervention ~ compound_roberta + (1| ID), data = sentiment_data, family = binomial)
summary(two_level_model)
# allowing to vary by ID
## 3-LEVEL MODEL (comments nested in ID nested in politicians):
three_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation), data = sentiment_data, family = binomial)
summary(three_level_model)
## 4-LEVEL MODEL (comments nested in ID nested in politicians nested in municipality):
four_level_model <- glmer(intervention ~ compound_roberta + (1| ID/name_abbreviation/municipality), data = sentiment_data, family = binomial)
summary(four_level_model)
## NO HIERARCHY MODEL
#a model with separate random intercepts for each grouping variable without explicitly specifying the nesting. This is assuming that the grouping variables are independent of each other.
no_hier_model <- glmer(intervention ~ compound_roberta + (1| ID) + (1| name_abbreviation) + (1| municipality), data = sentiment_data, family = binomial)
summary(no_hier_model)
#maybe make a model only varying by ID, 1 only my politician, 1 only by municipality?
#compare the different models like this:
f1 <- performance::model_performance(empty_model, metrics= "common")
f2 <- performance::model_performance(no_mixed_model, metrics= "common")
f3 <- performance::model_performance(two_level_model, metrics= "common")
f4 <- performance::model_performance(three_level_model, metrics= "common")
f5 <- performance::model_performance(four_level_model, metrics= "common")
f6 <- performance::model_performance(no_hier_model, metrics= "common")
print("empty_model:")
f1
print("no_mixed_model:")
f2
print("two_level_model:")
f3
print("three_level_model:")
f4
print("four_level_model:")
f5
print("no_hier_model:")
f6
# The empty model and and the 2 level models has the lowest AIC indicating better model performance
#can do some simple plotting
plot(pos_score_roberta ~ neg_score_roberta, data = sentiment_data, main = "pos_score_roberta ~ neg_score_roberta")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(magrittr)
data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/all_files_final.csv',show_col_types = FALSE)
View(data)
#how many different politician as part of intervention
unique_int <- data %>%
filter(intervention == "yes") %>%
unique_int <- table(unique_int$name_abbreviation) # Count unique occurrences
#how many different politician as part of intervention
unique_int <- data %>%
filter(intervention == "yes")
unique_int <- table(unique_int$name_abbreviation) # Count unique occurrences
print(unique_int) # Print the counts
total_unique <- length(unique_int(data$name_abbreviation))
total_unique <- length(unique(unique_int$name_abbreviation))
#how many different politician as part of intervention
unique_int <- data %>%
filter(intervention == "yes")
unique_int <- table(unique_int$name_abbreviation) # Count unique occurrences
print(unique_int) # Print the counts
total_unique <- length(unique(unique_int$name_abbreviation))
#counts:
#how many posts: 1601
data$main_post <- as.numeric(data$main_post)
sum(data$main_post)
#how many different politicians: 77
unique_counts <- table(data$name_abbreviation) # Count unique occurrences
print(unique_counts) # Print the counts
total_unique <- length(unique(data$name_abbreviation))
print(total_unique)  # Print the total number of unique occurrences
#how many politicians from aarhus: 27
unique_aarhus <- data %>%
filter(municipality == "aarhus") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique_aarhus) # Print the result
#how many politicians from copenhagen: 50
unique_copenhagen <- data %>%
filter(municipality == "copenhagen") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique_copenhagen) # Print the result
#how many different politician as part of intervention
unique_int <- data %>%
filter(intervention == "yes")
unique_int <- table(unique_int$name_abbreviation) # Count unique occurrences
print(unique_int) # Print the counts
total_unique <- length(unique(unique_int$name_abbreviation))
View(data)
#how many different politician as part of intervention
unique_int <- data %>%
select(intervention == "yes")
library(tidyverse)
library(dplyr)
library(magrittr)
data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/all_files_final.csv',show_col_types = FALSE)
#counts:
#how many posts: 1601
data$main_post <- as.numeric(data$main_post)
sum(data$main_post)
#how many different politicians: 77
unique_counts <- table(data$name_abbreviation) # Count unique occurrences
print(unique_counts) # Print the counts
total_unique <- length(unique(data$name_abbreviation))
print(total_unique)  # Print the total number of unique occurrences
#how many politicians from aarhus: 27
unique_aarhus <- data %>%
filter(municipality == "aarhus") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique_aarhus) # Print the result
#how many politicians from copenhagen: 50
unique_copenhagen <- data %>%
filter(municipality == "copenhagen") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique_copenhagen) # Print the result
#how many different politician as part of intervention
unique_int <- data %>%
select(intervention == "yes")
#how many different politician as part of intervention
unique_int <- data %>%
select(intervention == yes)
unique_copenhagen <- data %>%
filter(municipality == "copenhagen") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique_copenhagen) # Print the result
unique <- data %>%
filter(intervention == "yes") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique) # Pri
unique_int <- table(unique_int$name_abbreviation) # Count unique occurrences
unique_int <- table(unique_int$name_abbreviation) # Count unique occurrences
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(magrittr)
data <- read_csv('/Users/idahelenedencker/Desktop/STANDBY/all_files_final.csv',show_col_types = FALSE)
#counts:
#how many posts: 1601
data$main_post <- as.numeric(data$main_post)
sum(data$main_post)
#how many different politicians: 77
unique_counts <- table(data$name_abbreviation) # Count unique occurrences
print(unique_counts) # Print the counts
total_unique <- length(unique(data$name_abbreviation))
print(total_unique)  # Print the total number of unique occurrences
#how many politicians from aarhus: 27
unique_aarhus <- data %>%
filter(municipality == "aarhus") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique_aarhus) # Print the result
#how many politicians from copenhagen: 50
unique_copenhagen <- data %>%
filter(municipality == "copenhagen") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique_copenhagen) # Print the result
#how many politicians in the intervention
unique <- data %>%
filter(intervention == "yes") %>%
pull(name_abbreviation) %>%
unique() %>%
length()
print(unique) # Print the result
